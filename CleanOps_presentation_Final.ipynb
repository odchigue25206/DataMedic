{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a1b435-18e6-482a-b1d0-43c32590d3dd",
   "metadata": {
    "id": "21a1b435-18e6-482a-b1d0-43c32590d3dd"
   },
   "source": [
    "# CleanOps\n",
    "### A Lightweight Toolkit for Dataset Inspection and Cleaning \n",
    "\n",
    "**Presented by:**  \n",
    "Angni, Sodais M.\n",
    " / Magtrayo, Harold Hope\n",
    " / Odchigue, Jave Melchor P.\n",
    " / Padillo, Reymart\n",
    " / Ruiz, Rynzo Rapheal R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6b3bc-4fec-44b6-9299-fb108a0fb18d",
   "metadata": {
    "id": "66c6b3bc-4fec-44b6-9299-fb108a0fb18d"
   },
   "source": [
    "##  Project Overview\n",
    "\n",
    "CleanOps is a lightweight toolkit that simplifies dataset preparation.\n",
    "\n",
    "It provides tools for:\n",
    "\n",
    "- Missing value detection  \n",
    "- Duplicate row detection  \n",
    "- Outlier detection  \n",
    "- Automatic cleaning  \n",
    "- Data organization  \n",
    "- Multi-format exporting  \n",
    "- Report generation  \n",
    "- End-to-end pipelines  \n",
    "\n",
    "**Purpose:** Make preprocessing fast and repeatable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d24cba-43c3-4e2c-9632-bf4558bcea66",
   "metadata": {},
   "source": [
    "# What's Inside the Project\n",
    "**data_getter.py**\n",
    "\n",
    "- Loads CSV and text files using pathlib\n",
    "\n",
    "- Encapsulation: Uses protected attribute _base_path to hide implementation details\n",
    "\n",
    "**data_preprocessor.py**\n",
    "\n",
    "- DataInspector – detects missing values, duplicates, and outliers\n",
    "\n",
    "    - Encapsulation: _data and _issues are protected; accessed via methods\n",
    "\n",
    "- DataCleaner – inherits from DataInspector (Inheritance)\n",
    "\n",
    "    - Overrides some methods to actually fix data (Polymorphism)\n",
    "\n",
    "    - Logs all fixes\n",
    "\n",
    "- DataOrganizer – standalone class for sorting rows/columns\n",
    "\n",
    "    - Uses protected _data attribute (Encapsulation)\n",
    "\n",
    "**data_output.py**\n",
    "\n",
    "- DataExporter – exports cleaned data to CSV, Excel, JSON\n",
    "\n",
    "- ReportGenerator – creates TXT summary reports\n",
    "\n",
    "- DataOutput – aggregates DataExporter and ReportGenerator (Composition)\n",
    "\n",
    "**data_pipeline.py**\n",
    "\n",
    "- Runs full workflow: Diagnose → Clean → Log fixes → Export → Generate report\n",
    "\n",
    "- Uses composition to combine cleaner, exporter, and reporter\n",
    "\n",
    "- Demonstrates polymorphism through cleaner treating different datasets with the same interface\n",
    "\n",
    "**Summary of OOP Concepts in CleanOps:**\n",
    "\n",
    "- Encapsulation: _data, _issues, _base_path\n",
    "\n",
    "- Inheritance: DataCleaner → DataInspector\n",
    "\n",
    "- Polymorphism: Overridden methods in DataCleaner and pipeline handling multiple classes uniformly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808c760-f22d-4383-95a9-280975a83726",
   "metadata": {
    "id": "f808c760-f22d-4383-95a9-280975a83726"
   },
   "source": [
    "# CleanOps Package Demo\n",
    "\n",
    "This notebook demonstrates **CleanOps**, a Python package for inspecting, cleaning, and exporting datasets.\n",
    "We will go **step-by-step**, showing how to detect duplicates, missing values, outliers, clean them, and generate reports.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79494d4-52cb-44de-b4f9-ed88a31d0f9d",
   "metadata": {
    "id": "c79494d4-52cb-44de-b4f9-ed88a31d0f9d"
   },
   "source": [
    "## Step 1: Install CleanOps\n",
    "If you haven't installed CleanOps yet, run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f29db-2f23-411f-86fd-8825e1cc4410",
   "metadata": {
    "id": "017f29db-2f23-411f-86fd-8825e1cc4410",
    "outputId": "52e50336-171c-45d5-d086-b1174aa86f0d"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade cleanops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9527c-2d0e-42b6-9a27-e0ca0b8643d0",
   "metadata": {
    "id": "21b9527c-2d0e-42b6-9a27-e0ca0b8643d0"
   },
   "source": [
    "## Step 2: Import Modules\n",
    "\n",
    "Import the required classes from CleanOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cd5c9-f4ba-4da1-bcd2-2fba25a94104",
   "metadata": {
    "id": "051cd5c9-f4ba-4da1-bcd2-2fba25a94104"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from cleanops import (\n",
    "    DataGetter,\n",
    "    DataInspector,\n",
    "    DataCleaner,\n",
    "    DataExporter,\n",
    "    ReportGenerator,\n",
    "    DataPipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f50321-09a1-4eb9-80dd-03f66cdff0ae",
   "metadata": {
    "id": "82f50321-09a1-4eb9-80dd-03f66cdff0ae"
   },
   "source": [
    "## Step 3: Load Dataset\n",
    "\n",
    "Load your CSV file using `DataGetter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde9a24-5aec-47cd-b45c-86a37760722f",
   "metadata": {
    "id": "8cde9a24-5aec-47cd-b45c-86a37760722f",
    "outputId": "f7cbad35-a2d1-48e9-dda6-9ed7945eb5c0"
   },
   "outputs": [],
   "source": [
    "getter = DataGetter(r\"C:\\Users\\jorda\\Documents\\GitHub\\CleanOps\\datasets\")  # Path to folder containing your dataset\n",
    "df = getter.read_csv(\"hotel_reservations_codeonly.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2854d58-151a-4a51-85d1-8c8e826b8851",
   "metadata": {
    "id": "c2854d58-151a-4a51-85d1-8c8e826b8851"
   },
   "source": [
    "## Step 4: Inspect Data\n",
    "\n",
    "Detect duplicates, missing values, and outliers using `DataInspector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b3a6f-f238-4a00-a9b5-ee1db036d37b",
   "metadata": {
    "id": "a06b3a6f-f238-4a00-a9b5-ee1db036d37b",
    "outputId": "42231bdf-f869-4b50-fcab-c19cc0f73c22"
   },
   "outputs": [],
   "source": [
    "inspector = DataInspector(df)\n",
    "\n",
    "# Detect duplicates\n",
    "duplicates = inspector.detect_duplicates()\n",
    "print(\"Duplicates Detected:\")\n",
    "for col, val in duplicates.items():\n",
    "    print(f\"- {col}: {val}\")\n",
    "\n",
    "# Detect missing values\n",
    "missing = inspector.detect_missing()\n",
    "print(\"\\nMissing Values Detected:\")\n",
    "for col, val in missing.items():\n",
    "    if val > 0:\n",
    "        print(f\"- {col}: {val} missing\")\n",
    "\n",
    "# Detect outliers\n",
    "outliers = inspector.detect_outliers()\n",
    "print(\"\\nOutliers Detected:\")\n",
    "for col, val in outliers.items():\n",
    "    if val > 0:\n",
    "        print(f\"- {col}: {val} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d8822-3c37-479f-8644-f4a52659aa63",
   "metadata": {
    "id": "bc4d8822-3c37-479f-8644-f4a52659aa63"
   },
   "source": [
    "## Step 5: Clean Data\n",
    "\n",
    "Fix duplicates and apply treatments using `DataCleaner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0d957-d8ed-4be0-a974-955a90b0508c",
   "metadata": {
    "id": "acf0d957-d8ed-4be0-a974-955a90b0508c",
    "outputId": "33b0795b-ff42-482a-be28-038700c91d81"
   },
   "outputs": [],
   "source": [
    "cleaner = DataCleaner(df)\n",
    "# Automatically remove duplicates per column\n",
    "cleaner.fix_duplicates()\n",
    "\n",
    "# Now treat only missing values and outliers\n",
    "cleaner.treat(treat_duplicates=False)\n",
    "\n",
    "# Show fix log\n",
    "print(\"\\nFix Log:\")\n",
    "for log in cleaner.get_fix_log():\n",
    "    print(\"-\", log)\n",
    "\n",
    "# Display cleaned data\n",
    "cleaner._data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7622f-9141-4e86-9de8-12c2890baa9b",
   "metadata": {
    "id": "14f7622f-9141-4e86-9de8-12c2890baa9b"
   },
   "source": [
    "## Step 6: Export Cleaned Data\n",
    "\n",
    "Save the cleaned dataset in multiple formats using `DataExporter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35c738-9159-41df-b3f0-8bc0db351f27",
   "metadata": {
    "id": "3b35c738-9159-41df-b3f0-8bc0db351f27",
    "outputId": "ac444982-f183-49b8-d8d5-483368c58658"
   },
   "outputs": [],
   "source": [
    "exporter = DataExporter(cleaner._data)\n",
    "exporter.to_csv(\"cleaned_data.csv\")\n",
    "exporter.to_excel(\"cleaned_data.xlsx\")\n",
    "exporter.to_json(\"cleaned_data.json\")\n",
    "print(\"Cleaned data exported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05750fc7-d271-4bbb-adf2-1988d16595dd",
   "metadata": {
    "id": "05750fc7-d271-4bbb-adf2-1988d16595dd"
   },
   "source": [
    "## Step 7: Generate a Report\n",
    "\n",
    "Summarize all data issues and export a report using `ReportGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d067df-c11f-49e8-8987-6aad2704e51c",
   "metadata": {
    "id": "01d067df-c11f-49e8-8987-6aad2704e51c",
    "outputId": "7c8e59a8-632a-4111-b87f-2f122b300634",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reporter = ReportGenerator(cleaner._data)\n",
    "report_summary = reporter.report()\n",
    "reporter.export_report(\"cleaning_report.txt\")\n",
    "print(\"Report generated.\")\n",
    "print(report_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684d1d16-0609-4322-b474-186adca3f78a",
   "metadata": {
    "id": "684d1d16-0609-4322-b474-186adca3f78a"
   },
   "source": [
    "## Step 8: Run Full Pipeline\n",
    "\n",
    "Combine cleaning, exporting, and reporting in a single `DataPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645cb85a-535f-4c1e-8fc8-9ec516b3f0f5",
   "metadata": {
    "id": "645cb85a-535f-4c1e-8fc8-9ec516b3f0f5",
    "outputId": "78905f72-0ba5-4b7b-8746-28ba64865e29"
   },
   "outputs": [],
   "source": [
    "pipeline = DataPipeline(cleaner=cleaner, exporter=exporter, reporter=reporter)\n",
    "pipeline\n",
    "pipeline.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f9117-ab59-471c-a0be-1d4faa0246db",
   "metadata": {
    "id": "9e1f9117-ab59-471c-a0be-1d4faa0246db"
   },
   "source": [
    "# Demo Complete\n",
    "\n",
    "You have successfully inspected, cleaned, exported, and reported on your dataset using CleanOps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179639e-6078-4157-85b9-3545c66ab96a",
   "metadata": {
    "id": "b179639e-6078-4157-85b9-3545c66ab96a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
